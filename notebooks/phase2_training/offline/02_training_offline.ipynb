{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 2 - Training with Unsloth + QLoRA (Offline Version)\n",
                "\n",
                "**Objective**: Fine-tune Qwen2.5-Coder-0.5B-Instruct using QLoRA on FIM dataset.\n",
                "\n",
                "**Environment**: Offline GPU machine"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "\n",
                "print(f\"NumPy version: {np.__version__}\")\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
                "else:\n",
                "    print(\"WARNING: No GPU detected!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# === CONFIG: Update paths as needed ===\n",
                "MODEL_PATH = '/app/models/Qwen2.5-Coder-0.5B-Instruct'  # Pre-downloaded model\n",
                "TRAIN_PATH = './split_data/train.jsonl'\n",
                "VAL_PATH = './split_data/val.jsonl'\n",
                "OUTPUT_DIR = './outputs'\n",
                "FINAL_MODEL_DIR = './final_model'\n",
                "\n",
                "import os\n",
                "assert os.path.exists(TRAIN_PATH), f\"Train file not found: {TRAIN_PATH}\"\n",
                "assert os.path.exists(VAL_PATH), f\"Val file not found: {VAL_PATH}\"\n",
                "print(\"✓ Data files found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from unsloth import FastLanguageModel\n",
                "\n",
                "max_seq_length = 2048\n",
                "dtype = None\n",
                "load_in_4bit = True\n",
                "\n",
                "print(f\"Loading model from {MODEL_PATH}...\")\n",
                "model, tokenizer = FastLanguageModel.from_pretrained(\n",
                "    model_name=MODEL_PATH,\n",
                "    max_seq_length=max_seq_length,\n",
                "    dtype=dtype,\n",
                "    load_in_4bit=load_in_4bit,\n",
                ")\n",
                "print(\"✓ Model loaded!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = FastLanguageModel.get_peft_model(\n",
                "    model,\n",
                "    r=16,\n",
                "    target_modules=[\n",
                "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
                "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
                "    ],\n",
                "    lora_alpha=16,\n",
                "    lora_dropout=0.05,\n",
                "    bias=\"none\",\n",
                "    use_gradient_checkpointing=\"unsloth\",\n",
                "    random_state=42,\n",
                ")\n",
                "print(\"✓ LoRA configured!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "print(\"Loading datasets...\")\n",
                "train_full = load_dataset('json', data_files=TRAIN_PATH, split='train')\n",
                "val_ds = load_dataset('json', data_files=VAL_PATH, split='train')\n",
                "\n",
                "# Use all training data\n",
                "train_ds = train_full\n",
                "print(f\"Train: {len(train_ds):,} samples\")\n",
                "print(f\"Val: {len(val_ds):,} samples\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import TrainingArguments\n",
                "from trl import SFTTrainer\n",
                "\n",
                "training_args = TrainingArguments(\n",
                "    output_dir=OUTPUT_DIR,\n",
                "    num_train_epochs=3,\n",
                "    per_device_train_batch_size=4,\n",
                "    per_device_eval_batch_size=4,\n",
                "    gradient_accumulation_steps=2,\n",
                "    learning_rate=5e-4,\n",
                "    lr_scheduler_type=\"cosine\",\n",
                "    warmup_ratio=0.05,\n",
                "    optim=\"adamw_8bit\",\n",
                "    weight_decay=0.01,\n",
                "    max_grad_norm=1.0,\n",
                "    logging_steps=50,\n",
                "    save_strategy=\"no\",\n",
                "    eval_strategy=\"no\",\n",
                "    fp16=not torch.cuda.is_bf16_supported(),\n",
                "    bf16=torch.cuda.is_bf16_supported(),\n",
                "    dataloader_num_workers=4,\n",
                "    group_by_length=True,\n",
                "    report_to=\"none\",\n",
                "    seed=42,\n",
                ")\n",
                "\n",
                "trainer = SFTTrainer(\n",
                "    model=model,\n",
                "    tokenizer=tokenizer,\n",
                "    train_dataset=train_ds,\n",
                "    eval_dataset=val_ds,\n",
                "    dataset_text_field=\"text\",\n",
                "    max_seq_length=max_seq_length,\n",
                "    args=training_args,\n",
                "    packing=True,\n",
                ")\n",
                "print(\"✓ Trainer initialized!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Starting training...\")\n",
                "trainer_stats = trainer.train()\n",
                "print(\"✓ Training complete!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs(FINAL_MODEL_DIR, exist_ok=True)\n",
                "\n",
                "model.save_pretrained(FINAL_MODEL_DIR)\n",
                "tokenizer.save_pretrained(FINAL_MODEL_DIR)\n",
                "print(f\"✓ Model saved to {FINAL_MODEL_DIR}\")\n",
                "\n",
                "# Zip for backup\n",
                "import shutil\n",
                "shutil.make_archive('final_model', 'zip', FINAL_MODEL_DIR)\n",
                "print(\"✓ Created final_model.zip\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}