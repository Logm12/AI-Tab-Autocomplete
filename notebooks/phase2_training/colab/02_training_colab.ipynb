{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTa6JZyfuYp9"
      },
      "source": [
        "# Phase 2 - Training with Unsloth + QLoRA\n",
        "\n",
        "**Objective**: Fine-tune Qwen2.5-Coder-0.5B-Instruct using QLoRA on FIM dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnGOJCIEuYp_"
      },
      "source": [
        "## Step 1: Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSRLr8dRuYp_",
        "outputId": "9b086123-9e72-4ce7-f868-9cba09997777"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"BFloat16 supported: {torch.cuda.is_bf16_supported()}\")\n",
        "else:\n",
        "    print(\"\\nWARNING: No GPU detected!\")\n",
        "    print(\"Please enable GPU: Runtime -> Change runtime type -> T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0lCUNFXuYqA"
      },
      "source": [
        "## Step 2: Install Unsloth and Dependencies\n",
        "\n",
        "This will take ~5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wO1w82y_uYqB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "\n",
        "print(\"Installation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfgvx7cIuYqB"
      },
      "source": [
        "## Step 3: Upload Training Data\n",
        "\n",
        "Upload `train.jsonl` and `val.jsonl` from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoyOY9lSuYqC",
        "outputId": "692feca6-02de-4004-ef1e-e7881cd1f2c8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "TRAIN_PATH = '/content/drive/MyDrive/train.jsonl'\n",
        "VAL_PATH = '/content/drive/MyDrive/val.jsonl'\n",
        "TEST_PATH = '/content/drive/MyDrive/test.jsonl'\n",
        "assert os.path.exists(TRAIN_PATH) and os.path.exists(VAL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0BngCiHuYqC"
      },
      "source": [
        "## Step 4: Load Base Model with QLoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "TUz4-9tmuYqC",
        "outputId": "a080b6bc-d43b-4c61-9631-99dc01a22aba"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "max_seq_length = 2048 # Updated for Phase 1 Data\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "print(\"Loading Qwen2.5-Coder-0.5B-Instruct...\")\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"Qwen/Qwen2.5-Coder-0.5B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")\n",
        "print(\"Model loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSesaU30uYqD"
      },
      "source": [
        "## Step 5: Configure LoRA Adapters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-ZOk1pTuYqD",
        "outputId": "83f0d1f5-e8e3-411d-8089-4c4df94b254d"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0.05,\n",
        "    bias = \"none\",\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 42,\n",
        ")\n",
        "print(\"LoRA configured!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ceY-g8HuYqD"
      },
      "source": [
        "## Step 6: Load and Prepare Datasets\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "LuPwLigyuYqE",
        "outputId": "a0c55e99-6f84-42f4-e494-2e82803d146c"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "print(\"\\nLoading data...\")\n",
        "train_full = load_dataset('json', data_files=TRAIN_PATH, split='train')\n",
        "val_ds = load_dataset('json', data_files=VAL_PATH, split='train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmDitKuqgJkU"
      },
      "source": [
        "## Train on 50% Dataset (Sampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO7SziPJgJZE",
        "outputId": "8c8d7e30-2415-4ab8-c7d2-dbed9ea8760e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "n_train = int(len(train_full))\n",
        "indices = torch.randperm(len(train_full))[:n_train]\n",
        "train_ds = train_full.select(indices)\n",
        "\n",
        "print(f\"Train: {len(train_ds):,} / {len(train_full):,} (50%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNTvdaOUuYqE"
      },
      "source": [
        "## Step 7: Configure Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_onkxjRhuYqE"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "from trl import SFTTrainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./outputs\",\n",
        "\n",
        "    num_train_epochs = 3,\n",
        "\n",
        "    per_device_train_batch_size = 4,\n",
        "    per_device_eval_batch_size = 4,\n",
        "    gradient_accumulation_steps = 2,\n",
        "\n",
        "    learning_rate = 5e-4,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    warmup_ratio = 0.05,\n",
        "\n",
        "    optim = \"adamw_8bit\",\n",
        "    weight_decay = 0.01,\n",
        "    max_grad_norm = 1.0,\n",
        "\n",
        "    logging_steps = 50,\n",
        "\n",
        "    save_strategy = \"no\",\n",
        "\n",
        "    eval_strategy = \"no\",\n",
        "\n",
        "    fp16 = not torch.cuda.is_bf16_supported(),\n",
        "    bf16 = torch.cuda.is_bf16_supported(),\n",
        "\n",
        "    dataloader_num_workers = 4,\n",
        "\n",
        "    group_by_length = True,\n",
        "    neftune_noise_alpha = 5,\n",
        "    report_to = \"none\",\n",
        "    load_best_model_at_end = False,\n",
        "    seed = 42,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPmnxvYKuYqE"
      },
      "source": [
        "## Step 8: Initialize Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "sUeRyyeJuYqE",
        "outputId": "1de16fd5-48b7-4f6e-9d28-1faec3683a1d"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset = val_ds,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    args = training_args,\n",
        "\n",
        "    packing = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjFt5Y_QuYqF"
      },
      "source": [
        "## Step 9: Start Training\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "Hghayn5MuYqF",
        "outputId": "49c69dac-26bb-4c40-df36-75d8ae1d1dd2"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1x_z22kuYqG"
      },
      "source": [
        "## Step 10: Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJj-X-cDuYqG",
        "outputId": "3499426f-4c57-4180-f00e-627237936a2a"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"final_model\")\n",
        "tokenizer.save_pretrained(\"final_model\")\n",
        "print(\"Model saved to final_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_jXgq_OuYqG"
      },
      "outputs": [],
      "source": [
        "# Zip for download\n",
        "!zip -r final_model.zip final_model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
